{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder,StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load datasets and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 ... 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = pd.read_csv('Dataset/csgo.csv')\n",
    "\n",
    "\n",
    "data = data.drop(['day', 'month', 'year', 'date',  \n",
    "                'team_a_rounds', 'team_b_rounds'], axis=1)\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "map_encoded = onehot_encoder.fit_transform(data[[\"map\"]]).toarray()  \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"result\"] = label_encoder.fit_transform(data[\"result\"])\n",
    "\n",
    "map_encoded_data = pd.DataFrame(map_encoded, columns=onehot_encoder.get_feature_names_out([\"map\"]))\n",
    "\n",
    "\n",
    "data = pd.concat([map_encoded_data, data.drop(columns=[\"map\"])], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = data.drop('result', axis=1)\n",
    "x = scaler.fit_transform(x)\n",
    "y = data['result']\n",
    "y = y.values.reshape(-1,)\n",
    "print(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split datasets into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(x_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using Multi Layer Perceptron to predict if new datasets, it will be lose or win or tie, we will try with only one hidden layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Cost: 1.0984862623534384\n",
      "Iteration 1000, Cost: 0.2413137475285645\n",
      "Iteration 2000, Cost: 0.1659694498177169\n",
      "Iteration 3000, Cost: 0.016147032122156794\n",
      "Iteration 4000, Cost: 0.007215102114106235\n",
      "Iteration 5000, Cost: 0.004436451348836866\n",
      "Iteration 6000, Cost: 0.003124613634228786\n",
      "Iteration 7000, Cost: 0.0023773234029422627\n",
      "Iteration 8000, Cost: 0.0019006218111765035\n",
      "Iteration 9000, Cost: 0.0015713275108854535\n"
     ]
    }
   ],
   "source": [
    "def softmax(V):\n",
    "    e_v = np.exp(V - np.max(V, axis=1, keepdims=True))\n",
    "    return e_v / e_v.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def convert_labels(y, C=3):\n",
    "    Y = np.zeros((len(y), C))  \n",
    "    Y[np.arange(len(y)), y] = 1\n",
    "    return Y\n",
    "\n",
    "\n",
    "def cost(Y, Ypred):\n",
    "    return -np.sum(Y * np.log(Ypred + 1e-8)) / Y.shape[0]  \n",
    "\n",
    "\n",
    "dim1 = x.shape[1]  \n",
    "unitLayer = 100\n",
    "dim2 = C = 3  \n",
    "N = x_train.shape[0]  \n",
    "\n",
    "Y = convert_labels(y_train, C) \n",
    "\n",
    "\n",
    "W1 = 0.01 * np.random.randn(dim1, unitLayer)\n",
    "b1 = np.zeros((1, unitLayer))\n",
    "W2 = 0.01 * np.random.randn(unitLayer, dim2)\n",
    "b2 = np.zeros((1, dim2))\n",
    "\n",
    "learningRate = 1\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "\n",
    "    # FeedForward\n",
    "\n",
    "    Z1 = np.dot(x_train, W1) + b1 \n",
    "    A1 = np.maximum(Z1, 0)  \n",
    "    Z2 = np.dot(A1, W2) + b2  \n",
    "    Ypred = softmax(Z2) \n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Iteration {i}, Cost: {cost(Y, Ypred)}\")\n",
    "\n",
    "    # Backpropagation\n",
    "    E2 = (Ypred - Y) / N  \n",
    "    dW2 = np.dot(A1.T, E2)  \n",
    "    db2 = np.sum(E2, axis=0, keepdims=True)  \n",
    "\n",
    "    E1 = np.dot(E2, W2.T)  \n",
    "    E1[Z1 <= 0] = 0  \n",
    "\n",
    "    dW1 = np.dot(x_train.T, E1)  \n",
    "    db1 = np.sum(E1, axis=0, keepdims=True)  \n",
    "    #Update weights and biases\n",
    "    W1 -= learningRate * dW1\n",
    "    b1 -= learningRate * db1\n",
    "    W2 -= learningRate * dW2\n",
    "    b2 -= learningRate * db2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Accuracy on test set: 68.28%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Z1_test = np.dot(x_test, W1) + b1  \n",
    "A1_test = np.maximum(Z1_test, 0)  \n",
    "Z2_test = np.dot(A1_test, W2) + b2  \n",
    "Ypred_test = softmax(Z2_test)  \n",
    "\n",
    "\n",
    "y_pred_labels = np.argmax(Ypred_test, axis=1)  \n",
    "\n",
    "\n",
    "accuracy = np.mean(y_pred_labels == y_test) * 100\n",
    "print(f\"ðŸŽ¯ Accuracy on test set: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "data = pd.read_csv('Dataset/csgo.csv')\n",
    "\n",
    "\n",
    "data = data.drop(['day', 'month', 'year', 'date', 'team_a_rounds', 'team_b_rounds'], axis=1)\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "map_encoded = onehot_encoder.fit_transform(data[[\"map\"]]).toarray()\n",
    "map_encoded_data = pd.DataFrame(map_encoded, columns=onehot_encoder.get_feature_names_out([\"map\"]))\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"result\"] = label_encoder.fit_transform(data[\"result\"])\n",
    "\n",
    "\n",
    "data = pd.concat([map_encoded_data, data.drop(columns=[\"map\"])], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = data.drop('result', axis=1)\n",
    "x = scaler.fit_transform(x)\n",
    "y = data['result'].values.reshape(-1,)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64, 32, 18), \n",
    "                    activation='relu',         \n",
    "                    solver='adam',             \n",
    "                    batch_size=32,             \n",
    "                    learning_rate_init=0.01,   \n",
    "                    max_iter=10000,            \n",
    "                    random_state=42)\n",
    "\n",
    "\n",
    "mlp.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = mlp.predict(x_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test set: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
